"""
Claude Code Router MCP - ç·©å­˜ç³»çµ±
é«˜æ•ˆçš„è«‹æ±‚éŸ¿æ‡‰ç·©å­˜å¯¦ç¾
"""

import asyncio
import json
import hashlib
import time
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """ç·©å­˜æ¢ç›®"""
    key: str
    value: Any
    created_at: float
    ttl: int
    access_count: int = 0
    last_access: float = 0
    
    def __post_init__(self):
        if self.last_access == 0:
            self.last_access = self.created_at
    
    def is_expired(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦éæœŸ"""
        return time.time() - self.created_at > self.ttl
    
    def update_access(self):
        """æ›´æ–°è¨ªå•çµ±è¨ˆ"""
        self.access_count += 1
        self.last_access = time.time()


class RouterCache:
    """è·¯ç”±å™¨ç·©å­˜ç³»çµ±"""
    
    def __init__(self, ttl: int = 3600, max_size: int = 1000):
        self.ttl = ttl
        self.max_size = max_size
        self.cache: Dict[str, CacheEntry] = {}
        self.stats = {
            "hits": 0,
            "misses": 0,
            "evictions": 0,
            "total_requests": 0
        }
        
        # å•Ÿå‹•æ¸…ç†ä»»å‹™
        self.cleanup_task = asyncio.create_task(self._cleanup_loop())
        
        logger.info(f"ğŸ“¦ RouterCache åˆå§‹åŒ–å®Œæˆ (TTL: {ttl}s, Max Size: {max_size})")
    
    async def get(self, key: str) -> Optional[Any]:
        """ç²å–ç·©å­˜å€¼"""
        self.stats["total_requests"] += 1
        
        if key not in self.cache:
            self.stats["misses"] += 1
            return None
        
        entry = self.cache[key]
        
        # æª¢æŸ¥éæœŸ
        if entry.is_expired():
            del self.cache[key]
            self.stats["misses"] += 1
            return None
        
        # æ›´æ–°è¨ªå•çµ±è¨ˆ
        entry.update_access()
        self.stats["hits"] += 1
        
        logger.debug(f"ğŸ¯ ç·©å­˜å‘½ä¸­: {key}")
        return entry.value
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """è¨­ç½®ç·©å­˜å€¼"""
        if ttl is None:
            ttl = self.ttl
        
        # æª¢æŸ¥å®¹é‡
        if len(self.cache) >= self.max_size:
            await self._evict_entries()
        
        # å‰µå»ºç·©å­˜æ¢ç›®
        entry = CacheEntry(
            key=key,
            value=value,
            created_at=time.time(),
            ttl=ttl
        )
        
        self.cache[key] = entry
        
        logger.debug(f"ğŸ’¾ ç·©å­˜è¨­ç½®: {key} (TTL: {ttl}s)")
        return True
    
    async def delete(self, key: str) -> bool:
        """åˆªé™¤ç·©å­˜å€¼"""
        if key in self.cache:
            del self.cache[key]
            logger.debug(f"ğŸ—‘ï¸ ç·©å­˜åˆªé™¤: {key}")
            return True
        return False
    
    async def clear(self):
        """æ¸…ç©ºç·©å­˜"""
        self.cache.clear()
        self.stats = {
            "hits": 0,
            "misses": 0,
            "evictions": 0,
            "total_requests": 0
        }
        logger.info("ğŸ§¹ ç·©å­˜å·²æ¸…ç©º")
    
    async def _evict_entries(self):
        """é©…é€ç·©å­˜æ¢ç›®"""
        if not self.cache:
            return
        
        # ç§»é™¤éæœŸæ¢ç›®
        expired_keys = [
            key for key, entry in self.cache.items()
            if entry.is_expired()
        ]
        
        for key in expired_keys:
            del self.cache[key]
            self.stats["evictions"] += 1
        
        # å¦‚æœé‚„éœ€è¦ç©ºé–“ï¼Œä½¿ç”¨LRUç­–ç•¥
        if len(self.cache) >= self.max_size:
            # æŒ‰æœ€å¾Œè¨ªå•æ™‚é–“æ’åº
            sorted_entries = sorted(
                self.cache.items(),
                key=lambda x: x[1].last_access
            )
            
            # é©…é€æœ€å°‘ä½¿ç”¨çš„æ¢ç›®
            evict_count = max(1, len(self.cache) // 10)  # é©…é€10%
            for key, _ in sorted_entries[:evict_count]:
                del self.cache[key]
                self.stats["evictions"] += 1
        
        logger.debug(f"ğŸ§¹ ç·©å­˜é©…é€å®Œæˆ: {len(expired_keys)} éæœŸ, {self.stats['evictions']} ç¸½é©…é€")
    
    async def _cleanup_loop(self):
        """æ¸…ç†å¾ªç’°"""
        while True:
            try:
                await asyncio.sleep(300)  # æ¯5åˆ†é˜æ¸…ç†ä¸€æ¬¡
                await self._evict_entries()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ç·©å­˜æ¸…ç†å¤±æ•—: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–ç·©å­˜çµ±è¨ˆ"""
        hit_rate = (self.stats["hits"] / self.stats["total_requests"] * 100) if self.stats["total_requests"] > 0 else 0
        
        return {
            "cache_size": len(self.cache),
            "max_size": self.max_size,
            "hit_rate": f"{hit_rate:.2f}%",
            "hits": self.stats["hits"],
            "misses": self.stats["misses"],
            "evictions": self.stats["evictions"],
            "total_requests": self.stats["total_requests"],
            "memory_usage": self._calculate_memory_usage()
        }
    
    def _calculate_memory_usage(self) -> str:
        """è¨ˆç®—è¨˜æ†¶é«”ä½¿ç”¨é‡"""
        total_size = 0
        for entry in self.cache.values():
            try:
                # ç²—ç•¥ä¼°ç®—
                total_size += len(json.dumps(entry.value, default=str))
            except:
                total_size += 1000  # é»˜èªå¤§å°
        
        if total_size < 1024:
            return f"{total_size} B"
        elif total_size < 1024 * 1024:
            return f"{total_size / 1024:.1f} KB"
        else:
            return f"{total_size / (1024 * 1024):.1f} MB"
    
    def get_cache_keys(self) -> List[str]:
        """ç²å–æ‰€æœ‰ç·©å­˜éµ"""
        return list(self.cache.keys())
    
    def get_cache_info(self, key: str) -> Optional[Dict[str, Any]]:
        """ç²å–ç·©å­˜æ¢ç›®ä¿¡æ¯"""
        if key not in self.cache:
            return None
        
        entry = self.cache[key]
        return {
            "key": key,
            "created_at": datetime.fromtimestamp(entry.created_at).isoformat(),
            "ttl": entry.ttl,
            "access_count": entry.access_count,
            "last_access": datetime.fromtimestamp(entry.last_access).isoformat(),
            "is_expired": entry.is_expired(),
            "size": len(json.dumps(entry.value, default=str))
        }
    
    async def extend_ttl(self, key: str, additional_ttl: int) -> bool:
        """å»¶é•·TTL"""
        if key not in self.cache:
            return False
        
        entry = self.cache[key]
        entry.ttl += additional_ttl
        
        logger.debug(f"â° TTLå»¶é•·: {key} (+{additional_ttl}s)")
        return True
    
    async def refresh_entry(self, key: str) -> bool:
        """åˆ·æ–°ç·©å­˜æ¢ç›®ï¼ˆé‡ç½®å‰µå»ºæ™‚é–“ï¼‰"""
        if key not in self.cache:
            return False
        
        entry = self.cache[key]
        entry.created_at = time.time()
        entry.update_access()
        
        logger.debug(f"ğŸ”„ ç·©å­˜åˆ·æ–°: {key}")
        return True
    
    async def get_popular_keys(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ç²å–æœ€å—æ­¡è¿çš„ç·©å­˜éµ"""
        sorted_entries = sorted(
            self.cache.items(),
            key=lambda x: x[1].access_count,
            reverse=True
        )
        
        return [
            {
                "key": key,
                "access_count": entry.access_count,
                "last_access": datetime.fromtimestamp(entry.last_access).isoformat()
            }
            for key, entry in sorted_entries[:limit]
        ]
    
    async def close(self):
        """é—œé–‰ç·©å­˜ç³»çµ±"""
        if self.cleanup_task:
            self.cleanup_task.cancel()
            try:
                await self.cleanup_task
            except asyncio.CancelledError:
                pass
        
        await self.clear()
        logger.info("ğŸ”’ RouterCache å·²é—œé–‰")


class SmartCache(RouterCache):
    """æ™ºèƒ½ç·©å­˜ç³»çµ±"""
    
    def __init__(self, ttl: int = 3600, max_size: int = 1000):
        super().__init__(ttl, max_size)
        self.model_cache_stats: Dict[str, Dict[str, Any]] = {}
        self.request_patterns: Dict[str, List[float]] = {}
    
    async def set_with_model_context(self, key: str, value: Any, 
                                   model_id: str, response_time: float,
                                   ttl: Optional[int] = None) -> bool:
        """å¸¶æ¨¡å‹ä¸Šä¸‹æ–‡çš„ç·©å­˜è¨­ç½®"""
        # æ›´æ–°æ¨¡å‹ç·©å­˜çµ±è¨ˆ
        if model_id not in self.model_cache_stats:
            self.model_cache_stats[model_id] = {
                "cache_count": 0,
                "avg_response_time": 0,
                "total_response_time": 0
            }
        
        stats = self.model_cache_stats[model_id]
        stats["cache_count"] += 1
        stats["total_response_time"] += response_time
        stats["avg_response_time"] = stats["total_response_time"] / stats["cache_count"]
        
        # æ ¹æ“šéŸ¿æ‡‰æ™‚é–“å‹•æ…‹èª¿æ•´TTL
        if ttl is None:
            if response_time > 5.0:  # æ…¢éŸ¿æ‡‰ç·©å­˜æ›´ä¹…
                ttl = self.ttl * 2
            elif response_time < 1.0:  # å¿«éŸ¿æ‡‰ç·©å­˜æ™‚é–“çŸ­
                ttl = self.ttl // 2
            else:
                ttl = self.ttl
        
        return await self.set(key, value, ttl)
    
    async def get_with_pattern_learning(self, key: str) -> Optional[Any]:
        """å¸¶æ¨¡å¼å­¸ç¿’çš„ç·©å­˜ç²å–"""
        # è¨˜éŒ„è«‹æ±‚æ¨¡å¼
        if key not in self.request_patterns:
            self.request_patterns[key] = []
        
        self.request_patterns[key].append(time.time())
        
        # åªä¿ç•™æœ€è¿‘çš„è«‹æ±‚è¨˜éŒ„
        cutoff_time = time.time() - 3600  # 1å°æ™‚
        self.request_patterns[key] = [
            t for t in self.request_patterns[key] if t > cutoff_time
        ]
        
        result = await self.get(key)
        
        # å¦‚æœæ˜¯é »ç¹è«‹æ±‚çš„é …ç›®ï¼Œè‡ªå‹•å»¶é•·TTL
        if result is not None and len(self.request_patterns[key]) > 5:
            await self.extend_ttl(key, 1800)  # å»¶é•·30åˆ†é˜
        
        return result
    
    def get_model_cache_stats(self) -> Dict[str, Dict[str, Any]]:
        """ç²å–æ¨¡å‹ç·©å­˜çµ±è¨ˆ"""
        return self.model_cache_stats
    
    def get_request_patterns(self) -> Dict[str, Any]:
        """ç²å–è«‹æ±‚æ¨¡å¼åˆ†æ"""
        patterns = {}
        
        for key, timestamps in self.request_patterns.items():
            if len(timestamps) > 1:
                intervals = [
                    timestamps[i] - timestamps[i-1]
                    for i in range(1, len(timestamps))
                ]
                
                patterns[key] = {
                    "request_count": len(timestamps),
                    "avg_interval": sum(intervals) / len(intervals) if intervals else 0,
                    "frequency": len(timestamps) / 3600,  # æ¯å°æ™‚è«‹æ±‚æ¬¡æ•¸
                    "last_request": datetime.fromtimestamp(timestamps[-1]).isoformat()
                }
        
        return patterns
    
    async def preload_popular_responses(self, popular_requests: List[Dict[str, Any]]):
        """é è¼‰å…¥æµè¡ŒéŸ¿æ‡‰"""
        for request_data in popular_requests:
            # é€™è£¡å¯ä»¥å¯¦ç¾é è¼‰å…¥é‚è¼¯
            # ä¾‹å¦‚ï¼šæå‰è¨ˆç®—å¸¸è¦‹è«‹æ±‚çš„éŸ¿æ‡‰ä¸¦ç·©å­˜
            pass
    
    def get_cache_efficiency(self) -> Dict[str, Any]:
        """ç²å–ç·©å­˜æ•ˆç‡åˆ†æ"""
        base_stats = self.get_stats()
        
        # è¨ˆç®—å¹³å‡è¨ªå•æ¬¡æ•¸
        total_access = sum(entry.access_count for entry in self.cache.values())
        avg_access = total_access / len(self.cache) if self.cache else 0
        
        # è¨ˆç®—ç†±é»æ•¸æ“šæ¯”ä¾‹
        hot_entries = sum(1 for entry in self.cache.values() if entry.access_count > avg_access)
        hot_ratio = hot_entries / len(self.cache) if self.cache else 0
        
        return {
            **base_stats,
            "avg_access_count": avg_access,
            "hot_data_ratio": f"{hot_ratio * 100:.1f}%",
            "model_stats": self.model_cache_stats,
            "active_patterns": len(self.request_patterns)
        }