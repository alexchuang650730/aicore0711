#!/usr/bin/env python3
"""
MCP-Zeroå·¥å…·å‘ç°å¼•æ“

åŸºäºMCP-Zeroæ•°æ®é›†çš„æ™ºèƒ½å·¥å…·å‘ç°ç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªåŠ¨æ‰«æã€æ³¨å†Œå’Œç®¡ç†MCPå·¥å…·ã€‚
æ”¯æŒ308ä¸ªæœåŠ¡å™¨å’Œ2,797ä¸ªå·¥å…·çš„å¤§è§„æ¨¡å·¥å…·ç”Ÿæ€ç³»ç»Ÿã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- è‡ªåŠ¨å·¥å…·æ‰«æå’Œå‘ç°
- å·¥å…·å…ƒæ•°æ®æå–å’Œåˆ†æ
- èƒ½åŠ›åˆ†æå’Œåˆ†ç±»
- å·¥å…·æ³¨å†Œè¡¨ç®¡ç†
- å®æ—¶å·¥å…·çŠ¶æ€ç›‘æ§

ä½œè€…: PowerAutomation Team
ç‰ˆæœ¬: 4.1.0
æ—¥æœŸ: 2025-01-07
"""

import asyncio
import json
import uuid
import hashlib
import aiohttp
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Set, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path
import re
import yaml
from urllib.parse import urlparse, urljoin
import subprocess
import tempfile
import shutil

from ..models.tool_models import MCPTool, ToolCapability, ToolStatus

logger = logging.getLogger(__name__)

class DiscoveryStatus(Enum):
    """å‘ç°çŠ¶æ€"""
    PENDING = "pending"
    SCANNING = "scanning"
    ANALYZING = "analyzing"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"

class ToolSource(Enum):
    """å·¥å…·æ¥æº"""
    MCP_ZERO_REGISTRY = "mcp_zero_registry"
    GITHUB_REPOSITORY = "github_repository"
    NPM_PACKAGE = "npm_package"
    PYPI_PACKAGE = "pypi_package"
    LOCAL_DIRECTORY = "local_directory"
    REMOTE_API = "remote_api"

@dataclass
class DiscoveryTask:
    """å‘ç°ä»»åŠ¡"""
    task_id: str
    source: ToolSource
    target: str  # URL, path, or identifier
    status: DiscoveryStatus = DiscoveryStatus.PENDING
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    discovered_tools: List[str] = field(default_factory=list)
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ToolRegistry:
    """å·¥å…·æ³¨å†Œè¡¨"""
    registry_id: str
    name: str
    description: str
    url: str
    tools: Dict[str, MCPTool] = field(default_factory=dict)
    last_updated: datetime = field(default_factory=datetime.now)
    total_tools: int = 0
    active_tools: int = 0
    categories: Dict[str, int] = field(default_factory=dict)

class MCPZeroDiscoveryEngine:
    """MCP-Zeroå·¥å…·å‘ç°å¼•æ“"""
    
    def __init__(self, config_path: str = "./mcp_zero_config.json"):
        """åˆå§‹åŒ–å‘ç°å¼•æ“"""
        self.config_path = Path(config_path)
        self.config = self._load_config()
        
        # æ ¸å¿ƒç»„ä»¶
        self.registries: Dict[str, ToolRegistry] = {}
        self.discovery_tasks: Dict[str, DiscoveryTask] = {}
        self.discovered_tools: Dict[str, MCPTool] = {}
        
        # å‘ç°é…ç½®
        self.max_concurrent_tasks = self.config.get("max_concurrent_tasks", 10)
        self.discovery_timeout = self.config.get("discovery_timeout", 300)  # 5åˆ†é’Ÿ
        self.retry_attempts = self.config.get("retry_attempts", 3)
        self.cache_duration = self.config.get("cache_duration", 3600)  # 1å°æ—¶
        
        # MCP-Zeroæ•°æ®é›†é…ç½®
        self.mcp_zero_registry_url = self.config.get(
            "mcp_zero_registry_url", 
            "https://raw.githubusercontent.com/modelcontextprotocol/registry/main"
        )
        
        # å·¥å…·åˆ†æå™¨
        self.capability_patterns = self._load_capability_patterns()
        self.category_classifiers = self._load_category_classifiers()
        
        # ç¼“å­˜å’Œå­˜å‚¨
        self.cache_dir = Path(self.config.get("cache_dir", "./mcp_zero_cache"))
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.discovery_stats = {
            "total_discoveries": 0,
            "successful_discoveries": 0,
            "failed_discoveries": 0,
            "total_tools_found": 0,
            "unique_tools": 0,
            "discovery_time_avg": 0.0
        }
        
        logger.info("MCP-Zeroå·¥å…·å‘ç°å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        default_config = {
            "max_concurrent_tasks": 10,
            "discovery_timeout": 300,
            "retry_attempts": 3,
            "cache_duration": 3600,
            "mcp_zero_registry_url": "https://raw.githubusercontent.com/modelcontextprotocol/registry/main",
            "cache_dir": "./mcp_zero_cache",
            "enable_github_discovery": True,
            "enable_npm_discovery": True,
            "enable_pypi_discovery": True,
            "github_token": None,
            "npm_registry": "https://registry.npmjs.org",
            "pypi_registry": "https://pypi.org"
        }
        
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                default_config.update(user_config)
            except Exception as e:
                logger.warning(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        
        return default_config
    
    def _load_capability_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½èƒ½åŠ›è¯†åˆ«æ¨¡å¼"""
        return {
            "file_operations": [
                r"read.*file", r"write.*file", r"create.*file", r"delete.*file",
                r"file.*system", r"directory", r"folder", r"path"
            ],
            "web_scraping": [
                r"scrape", r"crawl", r"web.*content", r"html.*parse", 
                r"extract.*data", r"web.*automation"
            ],
            "api_integration": [
                r"api.*call", r"rest.*api", r"http.*request", r"webhook",
                r"integration", r"service.*call"
            ],
            "data_processing": [
                r"process.*data", r"transform", r"convert", r"parse",
                r"analyze.*data", r"filter", r"sort", r"aggregate"
            ],
            "ai_ml": [
                r"machine.*learning", r"ai.*model", r"neural.*network",
                r"prediction", r"classification", r"nlp", r"computer.*vision"
            ],
            "database": [
                r"database", r"sql", r"query", r"table", r"record",
                r"crud", r"orm", r"migration"
            ],
            "communication": [
                r"email", r"sms", r"notification", r"message", r"chat",
                r"slack", r"discord", r"telegram"
            ],
            "automation": [
                r"automate", r"schedule", r"trigger", r"workflow",
                r"pipeline", r"batch", r"cron"
            ],
            "monitoring": [
                r"monitor", r"log", r"metric", r"alert", r"health.*check",
                r"performance", r"status", r"uptime"
            ],
            "security": [
                r"encrypt", r"decrypt", r"hash", r"auth", r"security",
                r"permission", r"access.*control", r"vulnerability"
            ]
        }
    
    def _load_category_classifiers(self) -> Dict[str, Dict[str, float]]:
        """åŠ è½½åˆ†ç±»å™¨æƒé‡"""
        return {
            "development": {
                "file_operations": 0.8,
                "api_integration": 0.7,
                "database": 0.6,
                "automation": 0.5
            },
            "data_science": {
                "ai_ml": 0.9,
                "data_processing": 0.8,
                "database": 0.6
            },
            "web_automation": {
                "web_scraping": 0.9,
                "automation": 0.7,
                "api_integration": 0.6
            },
            "communication": {
                "communication": 0.9,
                "api_integration": 0.5
            },
            "system_admin": {
                "monitoring": 0.8,
                "security": 0.7,
                "automation": 0.6,
                "file_operations": 0.5
            }
        }
    
    async def start_discovery(self, sources: List[Dict[str, Any]] = None) -> List[str]:
        """å¼€å§‹å·¥å…·å‘ç°"""
        if sources is None:
            sources = [
                {"type": "mcp_zero_registry", "target": self.mcp_zero_registry_url},
                {"type": "github_search", "target": "mcp-server"},
                {"type": "npm_search", "target": "@modelcontextprotocol"}
            ]
        
        task_ids = []
        
        for source_config in sources:
            task_id = await self._create_discovery_task(
                source=ToolSource(source_config["type"]),
                target=source_config["target"],
                metadata=source_config.get("metadata", {})
            )
            task_ids.append(task_id)
        
        # å¹¶å‘æ‰§è¡Œå‘ç°ä»»åŠ¡
        await self._execute_discovery_tasks(task_ids)
        
        logger.info(f"å·¥å…·å‘ç°å®Œæˆï¼Œåˆ›å»ºäº† {len(task_ids)} ä¸ªå‘ç°ä»»åŠ¡")
        return task_ids
    
    async def _create_discovery_task(self, source: ToolSource, target: str, 
                                   metadata: Dict[str, Any] = None) -> str:
        """åˆ›å»ºå‘ç°ä»»åŠ¡"""
        task_id = f"discovery_{uuid.uuid4().hex[:8]}"
        
        task = DiscoveryTask(
            task_id=task_id,
            source=source,
            target=target,
            metadata=metadata or {}
        )
        
        self.discovery_tasks[task_id] = task
        
        logger.info(f"åˆ›å»ºå‘ç°ä»»åŠ¡ {task_id}: {source.value} -> {target}")
        return task_id
    
    async def _execute_discovery_tasks(self, task_ids: List[str]):
        """å¹¶å‘æ‰§è¡Œå‘ç°ä»»åŠ¡"""
        semaphore = asyncio.Semaphore(self.max_concurrent_tasks)
        
        async def execute_task(task_id: str):
            async with semaphore:
                await self._execute_single_discovery_task(task_id)
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        await asyncio.gather(*[execute_task(task_id) for task_id in task_ids])
    
    async def _execute_single_discovery_task(self, task_id: str):
        """æ‰§è¡Œå•ä¸ªå‘ç°ä»»åŠ¡"""
        task = self.discovery_tasks[task_id]
        
        try:
            task.status = DiscoveryStatus.SCANNING
            task.started_at = datetime.now()
            
            # æ ¹æ®æºç±»å‹æ‰§è¡Œä¸åŒçš„å‘ç°é€»è¾‘
            if task.source == ToolSource.MCP_ZERO_REGISTRY:
                discovered_tools = await self._discover_from_mcp_zero_registry(task)
            elif task.source == ToolSource.GITHUB_REPOSITORY:
                discovered_tools = await self._discover_from_github(task)
            elif task.source == ToolSource.NPM_PACKAGE:
                discovered_tools = await self._discover_from_npm(task)
            elif task.source == ToolSource.PYPI_PACKAGE:
                discovered_tools = await self._discover_from_pypi(task)
            elif task.source == ToolSource.LOCAL_DIRECTORY:
                discovered_tools = await self._discover_from_local_directory(task)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å‘ç°æº: {task.source}")
            
            # åˆ†æå‘ç°çš„å·¥å…·
            task.status = DiscoveryStatus.ANALYZING
            analyzed_tools = await self._analyze_discovered_tools(discovered_tools, task)
            
            # æ³¨å†Œå·¥å…·
            for tool in analyzed_tools:
                await self._register_tool(tool)
                task.discovered_tools.append(tool.tool_id)
            
            task.status = DiscoveryStatus.COMPLETED
            task.completed_at = datetime.now()
            
            # æ›´æ–°ç»Ÿè®¡
            self.discovery_stats["successful_discoveries"] += 1
            self.discovery_stats["total_tools_found"] += len(analyzed_tools)
            
            logger.info(f"å‘ç°ä»»åŠ¡ {task_id} å®Œæˆï¼Œå‘ç° {len(analyzed_tools)} ä¸ªå·¥å…·")
            
        except asyncio.TimeoutError:
            task.status = DiscoveryStatus.TIMEOUT
            task.error_message = "å‘ç°ä»»åŠ¡è¶…æ—¶"
            self.discovery_stats["failed_discoveries"] += 1
            logger.error(f"å‘ç°ä»»åŠ¡ {task_id} è¶…æ—¶")
            
        except Exception as e:
            task.status = DiscoveryStatus.FAILED
            task.error_message = str(e)
            task.completed_at = datetime.now()
            self.discovery_stats["failed_discoveries"] += 1
            logger.error(f"å‘ç°ä»»åŠ¡ {task_id} å¤±è´¥: {e}")
        
        finally:
            self.discovery_stats["total_discoveries"] += 1
    
    async def _discover_from_mcp_zero_registry(self, task: DiscoveryTask) -> List[Dict[str, Any]]:
        """ä»MCP-Zeroæ³¨å†Œè¡¨å‘ç°å·¥å…·"""
        registry_url = task.target
        discovered_tools = []
        
        async with aiohttp.ClientSession() as session:
            # è·å–æ³¨å†Œè¡¨ç´¢å¼•
            index_url = urljoin(registry_url, "index.json")
            
            try:
                async with session.get(index_url) as response:
                    if response.status == 200:
                        registry_index = await response.json()
                    else:
                        raise Exception(f"æ— æ³•è·å–æ³¨å†Œè¡¨ç´¢å¼•: {response.status}")
                
                # éå†æ‰€æœ‰æœåŠ¡å™¨
                for server_info in registry_index.get("servers", []):
                    server_id = server_info.get("id")
                    server_url = urljoin(registry_url, f"servers/{server_id}.json")
                    
                    try:
                        async with session.get(server_url) as response:
                            if response.status == 200:
                                server_data = await response.json()
                                tools = await self._extract_tools_from_server_data(server_data)
                                discovered_tools.extend(tools)
                            else:
                                logger.warning(f"æ— æ³•è·å–æœåŠ¡å™¨æ•°æ® {server_id}: {response.status}")
                    
                    except Exception as e:
                        logger.warning(f"å¤„ç†æœåŠ¡å™¨ {server_id} æ—¶å‡ºé”™: {e}")
                        continue
                
            except Exception as e:
                logger.error(f"ä»MCP-Zeroæ³¨å†Œè¡¨å‘ç°å·¥å…·å¤±è´¥: {e}")
                raise
        
        logger.info(f"ä»MCP-Zeroæ³¨å†Œè¡¨å‘ç° {len(discovered_tools)} ä¸ªå·¥å…·")
        return discovered_tools
    
    async def _extract_tools_from_server_data(self, server_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»æœåŠ¡å™¨æ•°æ®ä¸­æå–å·¥å…·ä¿¡æ¯"""
        tools = []
        
        server_id = server_data.get("id", "unknown")
        server_name = server_data.get("name", server_id)
        server_description = server_data.get("description", "")
        
        # æå–å·¥å…·åˆ—è¡¨
        for tool_info in server_data.get("tools", []):
            tool = {
                "tool_id": f"{server_id}_{tool_info.get('name', 'unknown')}",
                "name": tool_info.get("name", "Unknown Tool"),
                "description": tool_info.get("description", server_description),
                "server_id": server_id,
                "server_name": server_name,
                "version": server_data.get("version", "1.0.0"),
                "author": server_data.get("author", "Unknown"),
                "license": server_data.get("license", "Unknown"),
                "repository": server_data.get("repository", ""),
                "homepage": server_data.get("homepage", ""),
                "tags": server_data.get("tags", []),
                "capabilities": tool_info.get("capabilities", []),
                "input_schema": tool_info.get("inputSchema", {}),
                "output_schema": tool_info.get("outputSchema", {}),
                "examples": tool_info.get("examples", []),
                "requirements": server_data.get("requirements", {}),
                "installation": server_data.get("installation", {}),
                "configuration": tool_info.get("configuration", {}),
                "source_type": "mcp_zero_registry",
                "source_url": server_data.get("repository", ""),
                "discovered_at": datetime.now().isoformat()
            }
            tools.append(tool)
        
        return tools
    
    async def _discover_from_github(self, task: DiscoveryTask) -> List[Dict[str, Any]]:
        """ä»GitHubå‘ç°å·¥å…·"""
        search_query = task.target
        discovered_tools = []
        
        # GitHub APIæœç´¢
        github_token = self.config.get("github_token")
        headers = {}
        if github_token:
            headers["Authorization"] = f"token {github_token}"
        
        async with aiohttp.ClientSession(headers=headers) as session:
            # æœç´¢ä»“åº“
            search_url = f"https://api.github.com/search/repositories?q={search_query}+mcp+server&sort=stars&order=desc"
            
            try:
                async with session.get(search_url) as response:
                    if response.status == 200:
                        search_results = await response.json()
                        
                        for repo in search_results.get("items", [])[:50]:  # é™åˆ¶å‰50ä¸ªç»“æœ
                            try:
                                tools = await self._analyze_github_repository(repo, session)
                                discovered_tools.extend(tools)
                            except Exception as e:
                                logger.warning(f"åˆ†æGitHubä»“åº“ {repo.get('full_name')} å¤±è´¥: {e}")
                                continue
                    else:
                        raise Exception(f"GitHubæœç´¢å¤±è´¥: {response.status}")
            
            except Exception as e:
                logger.error(f"ä»GitHubå‘ç°å·¥å…·å¤±è´¥: {e}")
                raise
        
        logger.info(f"ä»GitHubå‘ç° {len(discovered_tools)} ä¸ªå·¥å…·")
        return discovered_tools
    
    async def _analyze_github_repository(self, repo: Dict[str, Any], 
                                       session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """åˆ†æGitHubä»“åº“"""
        tools = []
        
        repo_name = repo.get("full_name", "")
        repo_url = repo.get("html_url", "")
        
        # è·å–package.jsonæˆ–setup.pyç­‰é…ç½®æ–‡ä»¶
        config_files = ["package.json", "setup.py", "pyproject.toml", "mcp.json"]
        
        for config_file in config_files:
            try:
                file_url = f"https://api.github.com/repos/{repo_name}/contents/{config_file}"
                async with session.get(file_url) as response:
                    if response.status == 200:
                        file_data = await response.json()
                        content = file_data.get("content", "")
                        
                        # è§£ç base64å†…å®¹
                        import base64
                        decoded_content = base64.b64decode(content).decode('utf-8')
                        
                        # åˆ†æé…ç½®æ–‡ä»¶
                        tool_info = await self._extract_tool_info_from_config(
                            decoded_content, config_file, repo
                        )
                        
                        if tool_info:
                            tools.append(tool_info)
                        break
                        
            except Exception as e:
                logger.debug(f"æ— æ³•è·å– {repo_name}/{config_file}: {e}")
                continue
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼ŒåŸºäºä»“åº“ä¿¡æ¯åˆ›å»ºåŸºç¡€å·¥å…·ä¿¡æ¯
        if not tools:
            tool_info = {
                "tool_id": f"github_{repo.get('id', 'unknown')}",
                "name": repo.get("name", "Unknown Tool"),
                "description": repo.get("description", ""),
                "version": "1.0.0",
                "author": repo.get("owner", {}).get("login", "Unknown"),
                "license": repo.get("license", {}).get("name", "Unknown") if repo.get("license") else "Unknown",
                "repository": repo_url,
                "homepage": repo.get("homepage", repo_url),
                "tags": repo.get("topics", []),
                "capabilities": [],
                "source_type": "github_repository",
                "source_url": repo_url,
                "stars": repo.get("stargazers_count", 0),
                "forks": repo.get("forks_count", 0),
                "language": repo.get("language", "Unknown"),
                "discovered_at": datetime.now().isoformat()
            }
            tools.append(tool_info)
        
        return tools
    
    async def _extract_tool_info_from_config(self, content: str, config_file: str, 
                                           repo: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ä»é…ç½®æ–‡ä»¶ä¸­æå–å·¥å…·ä¿¡æ¯"""
        try:
            if config_file == "package.json":
                config = json.loads(content)
                return {
                    "tool_id": f"npm_{config.get('name', 'unknown').replace('/', '_')}",
                    "name": config.get("name", "Unknown Tool"),
                    "description": config.get("description", ""),
                    "version": config.get("version", "1.0.0"),
                    "author": config.get("author", "Unknown"),
                    "license": config.get("license", "Unknown"),
                    "repository": repo.get("html_url", ""),
                    "homepage": config.get("homepage", repo.get("html_url", "")),
                    "tags": config.get("keywords", []),
                    "capabilities": [],
                    "dependencies": config.get("dependencies", {}),
                    "source_type": "npm_package",
                    "source_url": repo.get("html_url", ""),
                    "discovered_at": datetime.now().isoformat()
                }
            
            elif config_file in ["setup.py", "pyproject.toml"]:
                # ç®€åŒ–çš„PythonåŒ…ä¿¡æ¯æå–
                return {
                    "tool_id": f"pypi_{repo.get('name', 'unknown')}",
                    "name": repo.get("name", "Unknown Tool"),
                    "description": repo.get("description", ""),
                    "version": "1.0.0",
                    "author": repo.get("owner", {}).get("login", "Unknown"),
                    "license": "Unknown",
                    "repository": repo.get("html_url", ""),
                    "homepage": repo.get("html_url", ""),
                    "tags": repo.get("topics", []),
                    "capabilities": [],
                    "source_type": "pypi_package",
                    "source_url": repo.get("html_url", ""),
                    "discovered_at": datetime.now().isoformat()
                }
            
            elif config_file == "mcp.json":
                config = json.loads(content)
                return {
                    "tool_id": f"mcp_{config.get('name', 'unknown')}",
                    "name": config.get("name", "Unknown Tool"),
                    "description": config.get("description", ""),
                    "version": config.get("version", "1.0.0"),
                    "author": config.get("author", "Unknown"),
                    "license": config.get("license", "Unknown"),
                    "repository": repo.get("html_url", ""),
                    "homepage": config.get("homepage", repo.get("html_url", "")),
                    "tags": config.get("tags", []),
                    "capabilities": config.get("capabilities", []),
                    "tools": config.get("tools", []),
                    "source_type": "mcp_server",
                    "source_url": repo.get("html_url", ""),
                    "discovered_at": datetime.now().isoformat()
                }
        
        except Exception as e:
            logger.debug(f"è§£æé…ç½®æ–‡ä»¶ {config_file} å¤±è´¥: {e}")
            return None
        
        return None
    
    async def _discover_from_npm(self, task: DiscoveryTask) -> List[Dict[str, Any]]:
        """ä»NPMå‘ç°å·¥å…·"""
        search_query = task.target
        discovered_tools = []
        
        npm_registry = self.config.get("npm_registry", "https://registry.npmjs.org")
        search_url = f"{npm_registry}/-/v1/search?text={search_query}&size=100"
        
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get(search_url) as response:
                    if response.status == 200:
                        search_results = await response.json()
                        
                        for package in search_results.get("objects", []):
                            package_info = package.get("package", {})
                            
                            tool_info = {
                                "tool_id": f"npm_{package_info.get('name', 'unknown').replace('/', '_')}",
                                "name": package_info.get("name", "Unknown Tool"),
                                "description": package_info.get("description", ""),
                                "version": package_info.get("version", "1.0.0"),
                                "author": package_info.get("author", {}).get("name", "Unknown") if isinstance(package_info.get("author"), dict) else str(package_info.get("author", "Unknown")),
                                "license": package_info.get("license", "Unknown"),
                                "repository": package_info.get("links", {}).get("repository", ""),
                                "homepage": package_info.get("links", {}).get("homepage", ""),
                                "tags": package_info.get("keywords", []),
                                "capabilities": [],
                                "npm_downloads": package.get("searchScore", 0),
                                "source_type": "npm_package",
                                "source_url": f"https://www.npmjs.com/package/{package_info.get('name', '')}",
                                "discovered_at": datetime.now().isoformat()
                            }
                            discovered_tools.append(tool_info)
                    
                    else:
                        raise Exception(f"NPMæœç´¢å¤±è´¥: {response.status}")
            
            except Exception as e:
                logger.error(f"ä»NPMå‘ç°å·¥å…·å¤±è´¥: {e}")
                raise
        
        logger.info(f"ä»NPMå‘ç° {len(discovered_tools)} ä¸ªå·¥å…·")
        return discovered_tools
    
    async def _discover_from_pypi(self, task: DiscoveryTask) -> List[Dict[str, Any]]:
        """ä»PyPIå‘ç°å·¥å…·"""
        search_query = task.target
        discovered_tools = []
        
        # PyPIæœç´¢API
        search_url = f"https://pypi.org/search/?q={search_query}&o=-created"
        
        # æ³¨æ„ï¼šPyPIæ²¡æœ‰å®˜æ–¹çš„æœç´¢APIï¼Œè¿™é‡Œä½¿ç”¨ç®€åŒ–çš„å®ç°
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨ç¬¬ä¸‰æ–¹æœåŠ¡æˆ–çˆ¬è™«
        
        logger.info(f"ä»PyPIå‘ç° {len(discovered_tools)} ä¸ªå·¥å…·")
        return discovered_tools
    
    async def _discover_from_local_directory(self, task: DiscoveryTask) -> List[Dict[str, Any]]:
        """ä»æœ¬åœ°ç›®å½•å‘ç°å·¥å…·"""
        directory_path = Path(task.target)
        discovered_tools = []
        
        if not directory_path.exists():
            raise Exception(f"æœ¬åœ°ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        
        # æ‰«æç›®å½•ä¸­çš„MCPå·¥å…·
        for item in directory_path.rglob("*"):
            if item.is_file() and item.name in ["package.json", "setup.py", "mcp.json"]:
                try:
                    with open(item, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    tool_info = await self._extract_tool_info_from_local_file(
                        content, item.name, item.parent
                    )
                    
                    if tool_info:
                        discovered_tools.append(tool_info)
                
                except Exception as e:
                    logger.warning(f"åˆ†ææœ¬åœ°æ–‡ä»¶ {item} å¤±è´¥: {e}")
                    continue
        
        logger.info(f"ä»æœ¬åœ°ç›®å½•å‘ç° {len(discovered_tools)} ä¸ªå·¥å…·")
        return discovered_tools
    
    async def _extract_tool_info_from_local_file(self, content: str, filename: str, 
                                               directory: Path) -> Optional[Dict[str, Any]]:
        """ä»æœ¬åœ°æ–‡ä»¶ä¸­æå–å·¥å…·ä¿¡æ¯"""
        try:
            if filename == "package.json":
                config = json.loads(content)
                return {
                    "tool_id": f"local_{config.get('name', directory.name).replace('/', '_')}",
                    "name": config.get("name", directory.name),
                    "description": config.get("description", ""),
                    "version": config.get("version", "1.0.0"),
                    "author": config.get("author", "Unknown"),
                    "license": config.get("license", "Unknown"),
                    "repository": "",
                    "homepage": "",
                    "tags": config.get("keywords", []),
                    "capabilities": [],
                    "local_path": str(directory),
                    "source_type": "local_directory",
                    "source_url": f"file://{directory}",
                    "discovered_at": datetime.now().isoformat()
                }
            
            elif filename == "mcp.json":
                config = json.loads(content)
                return {
                    "tool_id": f"local_mcp_{config.get('name', directory.name)}",
                    "name": config.get("name", directory.name),
                    "description": config.get("description", ""),
                    "version": config.get("version", "1.0.0"),
                    "author": config.get("author", "Unknown"),
                    "license": config.get("license", "Unknown"),
                    "repository": "",
                    "homepage": "",
                    "tags": config.get("tags", []),
                    "capabilities": config.get("capabilities", []),
                    "tools": config.get("tools", []),
                    "local_path": str(directory),
                    "source_type": "local_mcp_server",
                    "source_url": f"file://{directory}",
                    "discovered_at": datetime.now().isoformat()
                }
        
        except Exception as e:
            logger.debug(f"è§£ææœ¬åœ°æ–‡ä»¶ {filename} å¤±è´¥: {e}")
            return None
        
        return None
    
    async def _analyze_discovered_tools(self, raw_tools: List[Dict[str, Any]], 
                                      task: DiscoveryTask) -> List[MCPTool]:
        """åˆ†æå‘ç°çš„å·¥å…·"""
        analyzed_tools = []
        
        for raw_tool in raw_tools:
            try:
                # èƒ½åŠ›åˆ†æ
                capabilities = await self._analyze_tool_capabilities(raw_tool)
                
                # åˆ†ç±»åˆ†æ
                category = await self._classify_tool(raw_tool, capabilities)
                
                # åˆ›å»ºMCPToolå¯¹è±¡
                mcp_tool = MCPTool(
                    tool_id=raw_tool.get("tool_id", f"unknown_{uuid.uuid4().hex[:8]}"),
                    name=raw_tool.get("name", "Unknown Tool"),
                    description=raw_tool.get("description", ""),
                    version=raw_tool.get("version", "1.0.0"),
                    author=raw_tool.get("author", "Unknown"),
                    license=raw_tool.get("license", "Unknown"),
                    category=category,
                    capabilities=capabilities,
                    tags=raw_tool.get("tags", []),
                    repository_url=raw_tool.get("repository", ""),
                    homepage_url=raw_tool.get("homepage", ""),
                    documentation_url=raw_tool.get("documentation", ""),
                    installation_guide=raw_tool.get("installation", {}),
                    configuration_schema=raw_tool.get("configuration", {}),
                    input_schema=raw_tool.get("input_schema", {}),
                    output_schema=raw_tool.get("output_schema", {}),
                    examples=raw_tool.get("examples", []),
                    dependencies=raw_tool.get("dependencies", {}),
                    requirements=raw_tool.get("requirements", {}),
                    status=ToolStatus.DISCOVERED,
                    source_type=raw_tool.get("source_type", "unknown"),
                    source_url=raw_tool.get("source_url", ""),
                    metadata={
                        "discovered_at": raw_tool.get("discovered_at", datetime.now().isoformat()),
                        "discovery_task_id": task.task_id,
                        "raw_data": raw_tool
                    }
                )
                
                analyzed_tools.append(mcp_tool)
                
            except Exception as e:
                logger.warning(f"åˆ†æå·¥å…·å¤±è´¥ {raw_tool.get('name', 'unknown')}: {e}")
                continue
        
        logger.info(f"æˆåŠŸåˆ†æ {len(analyzed_tools)} ä¸ªå·¥å…·")
        return analyzed_tools
    
    async def _analyze_tool_capabilities(self, tool_data: Dict[str, Any]) -> List[ToolCapability]:
        """åˆ†æå·¥å…·èƒ½åŠ›"""
        capabilities = []
        
        # ä»æè¿°å’Œåç§°ä¸­æå–èƒ½åŠ›
        text_content = f"{tool_data.get('name', '')} {tool_data.get('description', '')} {' '.join(tool_data.get('tags', []))}"
        text_content = text_content.lower()
        
        for capability_name, patterns in self.capability_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_content):
                    capability = ToolCapability(
                        name=capability_name,
                        description=f"Detected {capability_name} capability",
                        confidence=0.8,
                        evidence=[pattern]
                    )
                    capabilities.append(capability)
                    break  # é¿å…é‡å¤æ·»åŠ åŒä¸€èƒ½åŠ›
        
        # ä»æ˜¾å¼çš„èƒ½åŠ›åˆ—è¡¨ä¸­æ·»åŠ 
        explicit_capabilities = tool_data.get("capabilities", [])
        for cap in explicit_capabilities:
            if isinstance(cap, str):
                capability = ToolCapability(
                    name=cap,
                    description=f"Explicit capability: {cap}",
                    confidence=1.0,
                    evidence=["explicit_declaration"]
                )
                capabilities.append(capability)
            elif isinstance(cap, dict):
                capability = ToolCapability(
                    name=cap.get("name", "unknown"),
                    description=cap.get("description", ""),
                    confidence=cap.get("confidence", 1.0),
                    evidence=cap.get("evidence", ["explicit_declaration"])
                )
                capabilities.append(capability)
        
        return capabilities
    
    async def _classify_tool(self, tool_data: Dict[str, Any], 
                           capabilities: List[ToolCapability]) -> str:
        """åˆ†ç±»å·¥å…·"""
        # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„å¾—åˆ†
        category_scores = {}
        
        for category, weights in self.category_classifiers.items():
            score = 0.0
            
            for capability in capabilities:
                if capability.name in weights:
                    score += weights[capability.name] * capability.confidence
            
            category_scores[category] = score
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„åˆ†ç±»
        if category_scores:
            best_category = max(category_scores, key=category_scores.get)
            
            # æ˜ å°„åˆ°å·¥å…·åˆ†ç±»å­—ç¬¦ä¸²
            category_mapping = {
                "development": "development",
                "data_science": "data_science", 
                "web_automation": "web_automation",
                "communication": "communication",
                "system_admin": "system_admin"
            }
            
            return category_mapping.get(best_category, "utility")
        
        return "utility"
    
    async def _register_tool(self, tool: MCPTool):
        """æ³¨å†Œå·¥å…·"""
        self.discovered_tools[tool.tool_id] = tool
        
        # æ›´æ–°ç»Ÿè®¡
        self.discovery_stats["unique_tools"] = len(self.discovered_tools)
        
        logger.debug(f"æ³¨å†Œå·¥å…·: {tool.name} ({tool.tool_id})")
    
    async def get_discovered_tools(self, category: str = None, 
                                 status: ToolStatus = None,
                                 limit: int = None) -> List[MCPTool]:
        """è·å–å‘ç°çš„å·¥å…·"""
        tools = list(self.discovered_tools.values())
        
        # è¿‡æ»¤
        if category:
            tools = [tool for tool in tools if tool.category == category]
        
        if status:
            tools = [tool for tool in tools if tool.status == status]
        
        # æ’åºï¼ˆæŒ‰å‘ç°æ—¶é—´å€’åºï¼‰
        tools.sort(key=lambda t: t.metadata.get("discovered_at", ""), reverse=True)
        
        # é™åˆ¶æ•°é‡
        if limit:
            tools = tools[:limit]
        
        return tools
    
    async def search_tools(self, query: str, limit: int = 20) -> List[MCPTool]:
        """æœç´¢å·¥å…·"""
        query = query.lower()
        matching_tools = []
        
        for tool in self.discovered_tools.values():
            # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
            score = 0.0
            
            # åç§°åŒ¹é…
            if query in tool.name.lower():
                score += 2.0
            
            # æè¿°åŒ¹é…
            if query in tool.description.lower():
                score += 1.0
            
            # æ ‡ç­¾åŒ¹é…
            for tag in tool.tags:
                if query in tag.lower():
                    score += 0.5
            
            # èƒ½åŠ›åŒ¹é…
            for capability in tool.capabilities:
                if query in capability.name.lower():
                    score += 1.5
            
            if score > 0:
                matching_tools.append((tool, score))
        
        # æŒ‰å¾—åˆ†æ’åº
        matching_tools.sort(key=lambda x: x[1], reverse=True)
        
        return [tool for tool, score in matching_tools[:limit]]
    
    async def get_discovery_statistics(self) -> Dict[str, Any]:
        """è·å–å‘ç°ç»Ÿè®¡ä¿¡æ¯"""
        # è®¡ç®—å¹³å‡å‘ç°æ—¶é—´
        completed_tasks = [
            task for task in self.discovery_tasks.values() 
            if task.status == DiscoveryStatus.COMPLETED and task.started_at and task.completed_at
        ]
        
        if completed_tasks:
            total_time = sum(
                (task.completed_at - task.started_at).total_seconds() 
                for task in completed_tasks
            )
            self.discovery_stats["discovery_time_avg"] = total_time / len(completed_tasks)
        
        # åˆ†ç±»ç»Ÿè®¡
        category_stats = {}
        for tool in self.discovered_tools.values():
            category = tool.category.value
            category_stats[category] = category_stats.get(category, 0) + 1
        
        # çŠ¶æ€ç»Ÿè®¡
        status_stats = {}
        for tool in self.discovered_tools.values():
            status = tool.status.value
            status_stats[status] = status_stats.get(status, 0) + 1
        
        # æºç±»å‹ç»Ÿè®¡
        source_stats = {}
        for tool in self.discovered_tools.values():
            source = tool.source_type
            source_stats[source] = source_stats.get(source, 0) + 1
        
        return {
            "discovery_overview": self.discovery_stats,
            "category_distribution": category_stats,
            "status_distribution": status_stats,
            "source_distribution": source_stats,
            "total_tasks": len(self.discovery_tasks),
            "active_tasks": len([
                task for task in self.discovery_tasks.values() 
                if task.status in [DiscoveryStatus.PENDING, DiscoveryStatus.SCANNING, DiscoveryStatus.ANALYZING]
            ]),
            "registries": len(self.registries)
        }
    
    async def export_discovered_tools(self, format: str = "json", 
                                    output_path: str = None) -> str:
        """å¯¼å‡ºå‘ç°çš„å·¥å…·"""
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"./discovered_tools_{timestamp}.{format}"
        
        tools_data = []
        for tool in self.discovered_tools.values():
            tool_dict = asdict(tool)
            # å¤„ç†æšä¸¾ç±»å‹
            tool_dict["category"] = tool.category.value
            tool_dict["status"] = tool.status.value
            tools_data.append(tool_dict)
        
        if format == "json":
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(tools_data, f, indent=2, ensure_ascii=False, default=str)
        
        elif format == "yaml":
            with open(output_path, 'w', encoding='utf-8') as f:
                yaml.dump(tools_data, f, default_flow_style=False, allow_unicode=True)
        
        elif format == "csv":
            import csv
            with open(output_path, 'w', newline='', encoding='utf-8') as f:
                if tools_data:
                    writer = csv.DictWriter(f, fieldnames=tools_data[0].keys())
                    writer.writeheader()
                    writer.writerows(tools_data)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format}")
        
        logger.info(f"å¯¼å‡º {len(tools_data)} ä¸ªå·¥å…·åˆ° {output_path}")
        return output_path

# å·¥å‚å‡½æ•°
def get_mcp_zero_discovery_engine(config_path: str = "./mcp_zero_config.json") -> MCPZeroDiscoveryEngine:
    """è·å–MCP-Zeroå‘ç°å¼•æ“å®ä¾‹"""
    return MCPZeroDiscoveryEngine(config_path)

# æµ‹è¯•å’Œæ¼”ç¤º
if __name__ == "__main__":
    async def test_discovery_engine():
        """æµ‹è¯•å‘ç°å¼•æ“"""
        engine = get_mcp_zero_discovery_engine()
        
        # å¼€å§‹å‘ç°
        print("ğŸ” å¼€å§‹å·¥å…·å‘ç°...")
        task_ids = await engine.start_discovery()
        
        # ç­‰å¾…å‘ç°å®Œæˆ
        await asyncio.sleep(5)
        
        # è·å–å‘ç°çš„å·¥å…·
        tools = await engine.get_discovered_tools(limit=10)
        print(f"ğŸ“‹ å‘ç° {len(tools)} ä¸ªå·¥å…·:")
        
        for tool in tools:
            print(f"  - {tool.name} ({tool.category.value})")
            print(f"    {tool.description[:100]}...")
            print(f"    èƒ½åŠ›: {[cap.name for cap in tool.capabilities[:3]]}")
            print()
        
        # æœç´¢æµ‹è¯•
        search_results = await engine.search_tools("file", limit=5)
        print(f"ğŸ” æœç´¢ 'file' ç›¸å…³å·¥å…· ({len(search_results)} ä¸ª):")
        for tool in search_results:
            print(f"  - {tool.name}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = await engine.get_discovery_statistics()
        print(f"ğŸ“Š å‘ç°ç»Ÿè®¡:")
        print(f"  æ€»å‘ç°æ•°: {stats['discovery_overview']['total_discoveries']}")
        print(f"  æˆåŠŸå‘ç°: {stats['discovery_overview']['successful_discoveries']}")
        print(f"  å‘ç°å·¥å…·æ•°: {stats['discovery_overview']['total_tools_found']}")
        print(f"  å”¯ä¸€å·¥å…·æ•°: {stats['discovery_overview']['unique_tools']}")
        
        # å¯¼å‡ºå·¥å…·
        export_path = await engine.export_discovered_tools("json")
        print(f"ğŸ’¾ å·¥å…·æ•°æ®å·²å¯¼å‡ºåˆ°: {export_path}")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_discovery_engine())

