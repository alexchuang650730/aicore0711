#!/usr/bin/env python3
"""
UIæµ‹è¯•æ¨¡æ¿æ‰§è¡Œå™¨

å°†æµ‹è¯•æ¨¡æ¿è½¬æ¢ä¸ºStagewiseæ¡†æ¶å¯æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹
"""

import json
import asyncio
import sys
import time
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.components.stagewise_mcp.enhanced_testing_framework import (
    EnhancedStagewiseTestingFramework,
    TestCase, TestSuite, TestPriority, TestCategory, TestStatus
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class TestStep:
    """æµ‹è¯•æ­¥éª¤æ•°æ®ç±»"""
    step_id: int
    action: str
    target: Optional[str] = None
    value: Optional[str] = None
    timeout: Optional[int] = None
    expected: Optional[str] = None
    description: str = ""
    width: Optional[int] = None
    height: Optional[int] = None
    filename: Optional[str] = None
    metric: Optional[str] = None
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TestStep':
        """ä»å­—å…¸åˆ›å»ºæµ‹è¯•æ­¥éª¤ï¼Œå¿½ç•¥æœªçŸ¥å‚æ•°"""
        known_fields = {f.name for f in cls.__dataclass_fields__.values()}
        filtered_data = {k: v for k, v in data.items() if k in known_fields}
        return cls(**filtered_data)
    
    def to_stagewise_action(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºStagewiseæ¡†æ¶åŠ¨ä½œæ ¼å¼"""
        action_data = {
            "type": self.action,
            "description": self.description
        }
        
        if self.target:
            action_data["selector"] = self.target
        if self.value:
            action_data["value"] = self.value
        if self.timeout:
            action_data["timeout"] = self.timeout
        if self.expected:
            action_data["expected"] = self.expected
            
        return action_data


@dataclass
class TestScenario:
    """æµ‹è¯•åœºæ™¯æ•°æ®ç±»"""
    scenario_id: str
    name: str
    description: str
    priority: str
    category: str
    estimated_duration: int
    pages: List[str]
    steps: List[TestStep]
    expected_results: List[str]
    test_data: Optional[Dict[str, Any]] = None
    viewports: Optional[List[Dict[str, Any]]] = None
    performance_thresholds: Optional[Dict[str, Any]] = None
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TestScenario':
        """ä»å­—å…¸åˆ›å»ºæµ‹è¯•åœºæ™¯"""
        steps = [TestStep.from_dict(step) for step in data.get('steps', [])]
        return cls(
            scenario_id=data['scenario_id'],
            name=data['name'],
            description=data['description'],
            priority=data['priority'],
            category=data['category'],
            estimated_duration=data['estimated_duration'],
            pages=data['pages'],
            steps=steps,
            expected_results=data['expected_results'],
            test_data=data.get('test_data'),
            viewports=data.get('viewports'),
            performance_thresholds=data.get('performance_thresholds')
        )
    
    def to_stagewise_test_case(self) -> TestCase:
        """è½¬æ¢ä¸ºStagewiseæµ‹è¯•ç”¨ä¾‹"""
        # è½¬æ¢ä¼˜å…ˆçº§
        priority_map = {
            "P0": TestPriority.P0,
            "P1": TestPriority.P1,
            "P2": TestPriority.P2
        }
        
        # è½¬æ¢åˆ†ç±»
        category_map = {
            "authentication": TestCategory.FUNCTIONAL,
            "navigation": TestCategory.FUNCTIONAL,
            "responsive": TestCategory.UI,
            "error_handling": TestCategory.FUNCTIONAL,
            "performance": TestCategory.PERFORMANCE
        }
        
        # æ„å»ºæµ‹è¯•åŠ¨ä½œ
        test_actions = []
        for step in self.steps:
            test_actions.append(step.to_stagewise_action())
        
        return TestCase(
            test_id=self.scenario_id,
            name=self.name,
            description=self.description,
            priority=priority_map.get(self.priority, TestPriority.P1),
            category=category_map.get(self.category, TestCategory.FUNCTIONAL),
            tags=[self.category, f"duration_{self.estimated_duration}s"],
            setup_actions=[],
            test_actions=test_actions,
            cleanup_actions=[],
            expected_results=self.expected_results,
            timeout=self.estimated_duration * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’
            retry_count=2,
            test_data=self.test_data or {}
        )


class UITestTemplateExecutor:
    """UIæµ‹è¯•æ¨¡æ¿æ‰§è¡Œå™¨"""
    
    def __init__(self, template_dir: str = "test_templates"):
        self.template_dir = Path(template_dir)
        self.scenarios_file = self.template_dir / "scenarios" / "ui_test_scenarios.json"
        self.pages_dir = self.template_dir / "pages"
        self.assets_dir = self.template_dir / "assets"
        self.framework = None
        self.scenarios: List[TestScenario] = []
        self.test_results = {}
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.assets_dir.mkdir(parents=True, exist_ok=True)
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–æ‰§è¡Œå™¨"""
        try:
            # åˆå§‹åŒ–Stagewiseæ¡†æ¶
            self.framework = EnhancedStagewiseTestingFramework()
            
            # åŠ è½½æµ‹è¯•åœºæ™¯
            await self.load_scenarios()
            
            # æ³¨å†Œæµ‹è¯•ç”¨ä¾‹åˆ°æ¡†æ¶
            await self.register_test_cases()
            
            logger.info(f"UIæµ‹è¯•æ¨¡æ¿æ‰§è¡Œå™¨åˆå§‹åŒ–æˆåŠŸï¼ŒåŠ è½½äº† {len(self.scenarios)} ä¸ªæµ‹è¯•åœºæ™¯")
            return True
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–UIæµ‹è¯•æ¨¡æ¿æ‰§è¡Œå™¨å¤±è´¥: {str(e)}")
            return False
    
    async def load_scenarios(self):
        """åŠ è½½æµ‹è¯•åœºæ™¯"""
        try:
            with open(self.scenarios_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.scenarios = []
            for scenario_data in data['test_scenarios']:
                scenario = TestScenario.from_dict(scenario_data)
                self.scenarios.append(scenario)
            
            logger.info(f"æˆåŠŸåŠ è½½ {len(self.scenarios)} ä¸ªæµ‹è¯•åœºæ™¯")
            
        except Exception as e:
            logger.error(f"åŠ è½½æµ‹è¯•åœºæ™¯å¤±è´¥: {str(e)}")
            raise
    
    async def register_test_cases(self):
        """æ³¨å†Œæµ‹è¯•ç”¨ä¾‹åˆ°Stagewiseæ¡†æ¶"""
        try:
            for scenario in self.scenarios:
                test_case = scenario.to_stagewise_test_case()
                self.framework.register_test_case(test_case)
            
            logger.info(f"æˆåŠŸæ³¨å†Œ {len(self.scenarios)} ä¸ªæµ‹è¯•ç”¨ä¾‹åˆ°Stagewiseæ¡†æ¶")
            
        except Exception as e:
            logger.error(f"æ³¨å†Œæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}")
            raise
    
    async def execute_scenario(self, scenario_id: str) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæµ‹è¯•åœºæ™¯"""
        try:
            scenario = next((s for s in self.scenarios if s.scenario_id == scenario_id), None)
            if not scenario:
                raise ValueError(f"æœªæ‰¾åˆ°æµ‹è¯•åœºæ™¯: {scenario_id}")
            
            logger.info(f"å¼€å§‹æ‰§è¡Œæµ‹è¯•åœºæ™¯: {scenario.name}")
            
            # å¯åŠ¨æµè§ˆå™¨ä¼šè¯
            session = await self.framework.start_browser_session()
            
            # è®¾ç½®åŸºç¡€URL
            base_url = f"file://{self.pages_dir.absolute()}"
            
            # æ‰§è¡Œæµ‹è¯•æ­¥éª¤
            step_results = []
            start_time = time.time()
            
            for step in scenario.steps:
                step_result = await self.execute_step(session, step, base_url)
                step_results.append(step_result)
                
                # å¦‚æœæ­¥éª¤å¤±è´¥ä¸”ä¸æ˜¯éªŒè¯æ­¥éª¤ï¼Œåœæ­¢æ‰§è¡Œ
                if not step_result['success'] and step.action != 'verify':
                    logger.warning(f"æ­¥éª¤ {step.step_id} å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
                    break
            
            end_time = time.time()
            duration = end_time - start_time
            
            # è®¡ç®—æˆåŠŸç‡
            successful_steps = sum(1 for r in step_results if r['success'])
            success_rate = successful_steps / len(step_results) if step_results else 0
            
            result = {
                "scenario_id": scenario_id,
                "scenario_name": scenario.name,
                "status": "PASSED" if success_rate >= 0.8 else "FAILED",
                "duration": duration,
                "success_rate": success_rate,
                "total_steps": len(scenario.steps),
                "successful_steps": successful_steps,
                "step_results": step_results,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # ä¿å­˜ç»“æœ
            self.test_results[scenario_id] = result
            
            logger.info(f"æµ‹è¯•åœºæ™¯ {scenario.name} æ‰§è¡Œå®Œæˆ: {result['status']} "
                       f"({successful_steps}/{len(step_results)} æ­¥éª¤æˆåŠŸ)")
            
            return result
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œæµ‹è¯•åœºæ™¯ {scenario_id} å¤±è´¥: {str(e)}")
            return {
                "scenario_id": scenario_id,
                "status": "ERROR",
                "error": str(e),
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
    
    async def execute_step(self, session, step: TestStep, base_url: str) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæµ‹è¯•æ­¥éª¤"""
        try:
            logger.info(f"æ‰§è¡Œæ­¥éª¤ {step.step_id}: {step.description}")
            
            step_start = time.time()
            success = True
            error_message = None
            screenshot_path = None
            
            if step.action == "navigate":
                # å¯¼èˆªåˆ°é¡µé¢
                url = f"{base_url}/{step.target}"
                await session.navigate(url)
                
            elif step.action == "wait":
                # ç­‰å¾…å…ƒç´ æˆ–æ—¶é—´
                timeout = step.timeout or 5000
                if step.target:
                    await session.wait_for_element(step.target, timeout)
                else:
                    await asyncio.sleep(timeout / 1000)
                    
            elif step.action == "input":
                # è¾“å…¥æ–‡æœ¬
                await session.input_text(step.target, step.value)
                
            elif step.action == "click":
                # ç‚¹å‡»å…ƒç´ 
                await session.click_element(step.target)
                
            elif step.action == "verify":
                # éªŒè¯å…ƒç´ å†…å®¹
                actual_text = await session.get_element_text(step.target)
                if step.expected not in actual_text:
                    success = False
                    error_message = f"éªŒè¯å¤±è´¥: æœŸæœ›åŒ…å« '{step.expected}', å®é™…ä¸º '{actual_text}'"
                    
            elif step.action == "screenshot":
                # æˆªå–å±å¹•æˆªå›¾
                screenshot_path = self.assets_dir / step.value
                await session.take_screenshot(str(screenshot_path))
                
            elif step.action == "set_viewport":
                # è®¾ç½®è§†å£å¤§å°
                await session.set_viewport(step.width, step.height)
                
            elif step.action == "accept_alert":
                # æ¥å—è­¦å‘Šå¯¹è¯æ¡†
                await session.accept_alert()
                
            elif step.action == "performance_start":
                # å¼€å§‹æ€§èƒ½ç›‘æ§
                await session.start_performance_monitoring()
                
            elif step.action == "performance_measure":
                # æµ‹é‡æ€§èƒ½æŒ‡æ ‡
                metrics = await session.get_performance_metrics()
                logger.info(f"æ€§èƒ½æŒ‡æ ‡: {metrics}")
                
            elif step.action == "performance_end":
                # ç»“æŸæ€§èƒ½ç›‘æ§
                await session.stop_performance_monitoring()
                
            else:
                logger.warning(f"æœªçŸ¥çš„æ­¥éª¤åŠ¨ä½œ: {step.action}")
            
            step_duration = time.time() - step_start
            
            return {
                "step_id": step.step_id,
                "action": step.action,
                "description": step.description,
                "success": success,
                "duration": step_duration,
                "error_message": error_message,
                "screenshot_path": str(screenshot_path) if screenshot_path else None
            }
            
        except Exception as e:
            step_duration = time.time() - step_start
            logger.error(f"æ­¥éª¤ {step.step_id} æ‰§è¡Œå¤±è´¥: {str(e)}")
            
            return {
                "step_id": step.step_id,
                "action": step.action,
                "description": step.description,
                "success": False,
                "duration": step_duration,
                "error_message": str(e),
                "screenshot_path": None
            }
    
    async def execute_all_scenarios(self) -> Dict[str, Any]:
        """æ‰§è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯"""
        logger.info("å¼€å§‹æ‰§è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯...")
        
        all_results = {}
        start_time = time.time()
        
        for scenario in self.scenarios:
            result = await self.execute_scenario(scenario.scenario_id)
            all_results[scenario.scenario_id] = result
        
        end_time = time.time()
        total_duration = end_time - start_time
        
        # ç»Ÿè®¡ç»“æœ
        total_scenarios = len(all_results)
        passed_scenarios = sum(1 for r in all_results.values() if r.get('status') == 'PASSED')
        failed_scenarios = total_scenarios - passed_scenarios
        
        summary = {
            "total_scenarios": total_scenarios,
            "passed_scenarios": passed_scenarios,
            "failed_scenarios": failed_scenarios,
            "success_rate": passed_scenarios / total_scenarios if total_scenarios > 0 else 0,
            "total_duration": total_duration,
            "results": all_results,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        logger.info(f"æ‰€æœ‰æµ‹è¯•åœºæ™¯æ‰§è¡Œå®Œæˆ: {passed_scenarios}/{total_scenarios} é€šè¿‡ "
                   f"({summary['success_rate']:.1%})")
        
        return summary
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report_lines = [
            "# UIæµ‹è¯•æ¨¡æ¿æ‰§è¡ŒæŠ¥å‘Š",
            "",
            f"**æ‰§è¡Œæ—¶é—´**: {results['timestamp']}",
            f"**æ€»åœºæ™¯æ•°**: {results['total_scenarios']}",
            f"**é€šè¿‡åœºæ™¯**: {results['passed_scenarios']}",
            f"**å¤±è´¥åœºæ™¯**: {results['failed_scenarios']}",
            f"**æˆåŠŸç‡**: {results['success_rate']:.1%}",
            f"**æ€»è€—æ—¶**: {results['total_duration']:.2f}ç§’",
            "",
            "## è¯¦ç»†ç»“æœ",
            ""
        ]
        
        for scenario_id, result in results['results'].items():
            status_emoji = "âœ…" if result['status'] == 'PASSED' else "âŒ"
            report_lines.extend([
                f"### {status_emoji} {result.get('scenario_name', scenario_id)}",
                "",
                f"- **çŠ¶æ€**: {result['status']}",
                f"- **è€—æ—¶**: {result.get('duration', 0):.2f}ç§’",
                f"- **æˆåŠŸç‡**: {result.get('success_rate', 0):.1%}",
                ""
            ])
            
            if 'step_results' in result:
                report_lines.append("**æ­¥éª¤è¯¦æƒ…**:")
                for step in result['step_results']:
                    step_emoji = "âœ…" if step['success'] else "âŒ"
                    report_lines.append(f"- {step_emoji} æ­¥éª¤{step['step_id']}: {step['description']} "
                                      f"({step['duration']:.2f}s)")
                    if step['error_message']:
                        report_lines.append(f"  - é”™è¯¯: {step['error_message']}")
                report_lines.append("")
        
        return "\n".join(report_lines)
    
    def save_report(self, results: Dict[str, Any], filename: str = None):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        if not filename:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"ui_test_template_report_{timestamp}.md"
        
        report_content = self.generate_report(results)
        report_path = self.assets_dir / filename
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return str(report_path)


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="UIæµ‹è¯•æ¨¡æ¿æ‰§è¡Œå™¨")
    parser.add_argument("--scenario", help="æ‰§è¡ŒæŒ‡å®šçš„æµ‹è¯•åœºæ™¯")
    parser.add_argument("--all", action="store_true", help="æ‰§è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºæ‰€æœ‰æµ‹è¯•åœºæ™¯")
    parser.add_argument("--template-dir", default="test_templates", help="æµ‹è¯•æ¨¡æ¿ç›®å½•")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæ‰§è¡Œå™¨
        executor = UITestTemplateExecutor(args.template_dir)
        
        # åˆå§‹åŒ–
        if not await executor.initialize():
            print("âŒ æ‰§è¡Œå™¨åˆå§‹åŒ–å¤±è´¥")
            sys.exit(1)
        
        if args.list:
            # åˆ—å‡ºæ‰€æœ‰æµ‹è¯•åœºæ™¯
            print("ğŸ“‹ å¯ç”¨çš„æµ‹è¯•åœºæ™¯:")
            for scenario in executor.scenarios:
                print(f"  - {scenario.scenario_id}: {scenario.name} [{scenario.priority}]")
                print(f"    {scenario.description}")
                print(f"    é¢„è®¡è€—æ—¶: {scenario.estimated_duration}ç§’")
                print()
        
        elif args.scenario:
            # æ‰§è¡ŒæŒ‡å®šåœºæ™¯
            print(f"ğŸ§ª æ‰§è¡Œæµ‹è¯•åœºæ™¯: {args.scenario}")
            result = await executor.execute_scenario(args.scenario)
            
            if result['status'] == 'PASSED':
                print(f"âœ… æµ‹è¯•åœºæ™¯æ‰§è¡ŒæˆåŠŸ")
            else:
                print(f"âŒ æµ‹è¯•åœºæ™¯æ‰§è¡Œå¤±è´¥")
            
            print(f"è¯¦ç»†ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}")
        
        elif args.all:
            # æ‰§è¡Œæ‰€æœ‰åœºæ™¯
            print("ğŸš€ æ‰§è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯...")
            results = await executor.execute_all_scenarios()
            
            # ä¿å­˜æŠ¥å‘Š
            report_path = executor.save_report(results)
            
            print(f"\nğŸ“Š æ‰§è¡Œæ‘˜è¦:")
            print(f"  æ€»åœºæ™¯æ•°: {results['total_scenarios']}")
            print(f"  é€šè¿‡åœºæ™¯: {results['passed_scenarios']}")
            print(f"  å¤±è´¥åœºæ™¯: {results['failed_scenarios']}")
            print(f"  æˆåŠŸç‡: {results['success_rate']:.1%}")
            print(f"  æ€»è€—æ—¶: {results['total_duration']:.2f}ç§’")
            print(f"  æŠ¥å‘Šæ–‡ä»¶: {report_path}")
        
        else:
            parser.print_help()
    
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())

